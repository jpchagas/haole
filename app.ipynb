{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48512762-d831-4b6a-878b-7d5c31ba62ef",
   "metadata": {},
   "source": [
    "# Create Train and Test Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "270a635d-4c75-416d-91c4-f1e4cbc7f8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f96464b5-20b6-4277-92f7-333def03464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH=\"/home/jpchagas/Downloads/20211025_Custom_Object_Detection_using_PyTorch_Faster_RCNN/wsl/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a7f194d-5b26-426a-b2c2-dc86de7a4745",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "220046d8-9372-4476-b2c4-d311aaf91dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_files = [x for x in files if x.endswith(\".xml\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72ab976a-4425-43b7-855c-f9f2aa1ae7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c28d713e-7de1-44c5-9af9-e48fae9740d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in xml_files:\n",
    "    try:\n",
    "        filename=file.replace(\".xml\",\".png\")\n",
    "        tree = ET.parse(BASE_PATH +file)\n",
    "        root = tree.getroot()\n",
    "        xml_path = root[2].text\n",
    "        ssize = root[4]\n",
    "        width = ssize[0].text\n",
    "        height = ssize[1].text\n",
    "        xml_object = root[6]\n",
    "        label = xml_object[0].text\n",
    "        coordinates = xml_object[4]\n",
    "        xmin = coordinates[0].text\n",
    "        ymin = coordinates[1].text\n",
    "        xmax = coordinates[2].text\n",
    "        ymax = coordinates[3].text\n",
    "        row = [filename,width,height,label,xmin,ymin,xmax,ymax]\n",
    "        data.append(row)\n",
    "    except:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a81627e1-917b-45d1-918e-27b88350ff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=['filename','width','height','class', 'xmin', 'ymin', 'xmax', 'ymax'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa8dc0e6-4e8a-4287-b5c4-97c8d1224a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aus_margaret_WebbWright_scene11971.png</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>surfer</td>\n",
       "      <td>560</td>\n",
       "      <td>305</td>\n",
       "      <td>634</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aus_margaret_WebbWright_scene11061.png</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>surfer</td>\n",
       "      <td>716</td>\n",
       "      <td>371</td>\n",
       "      <td>917</td>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aus_margaret_WebbGilmore_scene08331.png</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>surfer</td>\n",
       "      <td>714</td>\n",
       "      <td>236</td>\n",
       "      <td>821</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aus_margaret_WebbGilmore_scene10641.png</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>surfer</td>\n",
       "      <td>718</td>\n",
       "      <td>332</td>\n",
       "      <td>877</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aus_margaret_WebbWright_scene11691.png</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>surfer</td>\n",
       "      <td>680</td>\n",
       "      <td>249</td>\n",
       "      <td>777</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>aus_margaret_WebbWright_scene18201.png</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>surfer</td>\n",
       "      <td>818</td>\n",
       "      <td>419</td>\n",
       "      <td>1016</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>aus_margaret_WebbWright_scene07071.png</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>surfer</td>\n",
       "      <td>624</td>\n",
       "      <td>404</td>\n",
       "      <td>808</td>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>aus_margaret_WebbWright_scene07001.png</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>surfer</td>\n",
       "      <td>849</td>\n",
       "      <td>215</td>\n",
       "      <td>923</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>aus_margaret_WebbWright_scene02241.png</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>surfer</td>\n",
       "      <td>717</td>\n",
       "      <td>255</td>\n",
       "      <td>826</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>aus_margaret_WebbWright_scene15681.png</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>surfer</td>\n",
       "      <td>707</td>\n",
       "      <td>220</td>\n",
       "      <td>814</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    filename width height   class xmin ymin  \\\n",
       "0     aus_margaret_WebbWright_scene11971.png  1280    720  surfer  560  305   \n",
       "1     aus_margaret_WebbWright_scene11061.png  1280    720  surfer  716  371   \n",
       "2    aus_margaret_WebbGilmore_scene08331.png  1280    720  surfer  714  236   \n",
       "3    aus_margaret_WebbGilmore_scene10641.png  1280    720  surfer  718  332   \n",
       "4     aus_margaret_WebbWright_scene11691.png  1280    720  surfer  680  249   \n",
       "..                                       ...   ...    ...     ...  ...  ...   \n",
       "189   aus_margaret_WebbWright_scene18201.png  1280    720  surfer  818  419   \n",
       "190   aus_margaret_WebbWright_scene07071.png  1280    720  surfer  624  404   \n",
       "191   aus_margaret_WebbWright_scene07001.png  1280    720  surfer  849  215   \n",
       "192   aus_margaret_WebbWright_scene02241.png  1280    720  surfer  717  255   \n",
       "193   aus_margaret_WebbWright_scene15681.png  1280    720  surfer  707  220   \n",
       "\n",
       "     xmax ymax  \n",
       "0     634  491  \n",
       "1     917  525  \n",
       "2     821  410  \n",
       "3     877  470  \n",
       "4     777  402  \n",
       "..    ...  ...  \n",
       "189  1016  568  \n",
       "190   808  545  \n",
       "191   923  300  \n",
       "192   826  386  \n",
       "193   814  429  \n",
       "\n",
       "[194 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5414ebaf-2dab-471d-be19-8a3c1bd51834",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3044c000-2d92-480c-baf9-242e5ab1be82",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_col = 'Label'\n",
    "X_cols = df.loc[:, df.columns != Y_col].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c31da3-bdc1-4423-bd3b-136aaa10fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[X_cols], df[Y_col],test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2092177c-2364-4d14-a142-e6b5b4b2f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42b445e",
   "metadata": {},
   "source": [
    "# Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e22fcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4 # increase / decrease according to GPU memeory\n",
    "RESIZE_TO = 512 # resize the image for training and transforms\n",
    "NUM_EPOCHS = 100 # number of epochs to train for\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# training images and XML files directory\n",
    "TRAIN_DIR = '../Microcontroller Detection/train'\n",
    "# validation images and XML files directory\n",
    "VALID_DIR = '../Microcontroller Detection/test'\n",
    "# classes: 0 index is reserved for background\n",
    "CLASS = 'surfer'\n",
    "NUM_CLASSES = 1\n",
    "# whether to visualize images after crearing the data loaders\n",
    "VISUALIZE_TRANSFORMED_IMAGES = False\n",
    "# location to save model and plots\n",
    "OUT_DIR = '../outputs'\n",
    "SAVE_PLOTS_EPOCH = 2 # save loss plots after these many epochs\n",
    "SAVE_MODEL_EPOCH = 2 # save model after these many epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b865950c",
   "metadata": {},
   "source": [
    "# Create dataset to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c178037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob as glob\n",
    "from xml.etree import ElementTree as et\n",
    "from config import CLASSES, RESIZE_TO, TRAIN_DIR, VALID_DIR, BATCH_SIZE\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import collate_fn, get_train_transform, get_valid_transform\n",
    "\n",
    "# the dataset class\n",
    "class SurferDataset(Dataset):\n",
    "    def __init__(self, dir_path, width, height, classes, transforms=None):\n",
    "        self.transforms = transforms\n",
    "        self.dir_path = dir_path\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.classes = classes\n",
    "        \n",
    "        # get all the image paths in sorted order\n",
    "        self.image_paths = glob.glob(f\"{self.dir_path}/*.jpg\")\n",
    "        self.all_images = [image_path.split('/')[-1] for image_path in self.image_paths]\n",
    "        self.all_images = sorted(self.all_images)\n",
    "    def __getitem__(self, idx):\n",
    "        # capture the image name and the full image path\n",
    "        image_name = self.all_images[idx]\n",
    "        image_path = os.path.join(self.dir_path, image_name)\n",
    "        # read the image\n",
    "        image = cv2.imread(image_path)\n",
    "        # convert BGR to RGB color format\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image_resized = cv2.resize(image, (self.width, self.height))\n",
    "        image_resized /= 255.0\n",
    "        \n",
    "        # capture the corresponding XML file for getting the annotations\n",
    "        annot_filename = image_name[:-4] + '.xml'\n",
    "        annot_file_path = os.path.join(self.dir_path, annot_filename)\n",
    "        \n",
    "        boxes = []\n",
    "        labels = []\n",
    "        tree = et.parse(annot_file_path)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # get the height and width of the image\n",
    "        image_width = image.shape[1]\n",
    "        image_height = image.shape[0]\n",
    "        \n",
    "        # box coordinates for xml files are extracted and corrected for image size given\n",
    "        for member in root.findall('object'):\n",
    "            # map the current object name to `classes` list to get...\n",
    "            # ... the label index and append to `labels` list\n",
    "            labels.append(self.classes.index(member.find('name').text))\n",
    "            \n",
    "            # xmin = left corner x-coordinates\n",
    "            xmin = int(member.find('bndbox').find('xmin').text)\n",
    "            # xmax = right corner x-coordinates\n",
    "            xmax = int(member.find('bndbox').find('xmax').text)\n",
    "            # ymin = left corner y-coordinates\n",
    "            ymin = int(member.find('bndbox').find('ymin').text)\n",
    "            # ymax = right corner y-coordinates\n",
    "            ymax = int(member.find('bndbox').find('ymax').text)\n",
    "            \n",
    "            # resize the bounding boxes according to the...\n",
    "            # ... desired `width`, `height`\n",
    "            xmin_final = (xmin/image_width)*self.width\n",
    "            xmax_final = (xmax/image_width)*self.width\n",
    "            ymin_final = (ymin/image_height)*self.height\n",
    "            yamx_final = (ymax/image_height)*self.height\n",
    "            \n",
    "            boxes.append([xmin_final, ymin_final, xmax_final, yamx_final])\n",
    "        \n",
    "        # bounding box to tensor\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        # area of the bounding boxes\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        # no crowd instances\n",
    "        iscrowd = torch.zeros((boxes.shape[0],), dtype=torch.int64)\n",
    "        # labels to tensor\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        # prepare the final `target` dictionary\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "        image_id = torch.tensor([idx])\n",
    "        target[\"image_id\"] = image_id\n",
    "        # apply the image transforms\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(image = image_resized,\n",
    "                                     bboxes = target['boxes'],\n",
    "                                     labels = labels)\n",
    "            image_resized = sample['image']\n",
    "            target['boxes'] = torch.Tensor(sample['bboxes'])\n",
    "            \n",
    "        return image_resized, target\n",
    "    def __len__(self):\n",
    "        return len(self.all_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce279a7",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354a844d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
